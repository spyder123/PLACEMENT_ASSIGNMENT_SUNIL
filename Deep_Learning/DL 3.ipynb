{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447343ae",
   "metadata": {},
   "source": [
    "***Question 3 -\n",
    "Train a Pure CNN with less than 10000 trainable parameters using the MNIST\n",
    "Dataset having minimum validation accuracy of 99.40%\n",
    "Note -***\n",
    "1. Code comments should be given for proper code understanding.\n",
    "\n",
    "2. Implement in both PyTorch and Tensorflow respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638ddb08",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e9e4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62b3a78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1d8d1bd9dd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2644e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations to apply to the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e52a841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:03<00:00, 2876289.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 1312995.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 3518839.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 2272248.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                      download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                     download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cee359cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloaders for training and testing\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "115c0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available and set device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9316911d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN with less than 10000 parameters\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, 64)\n",
    "        self.fc2 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c0c8924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the CNN model\n",
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52bacc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f05c7ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Loss: 0.3854492844771475\n",
      "[2] Loss: 0.09480279464044296\n",
      "[3] Loss: 0.06730267057008645\n",
      "[4] Loss: 0.05138291248769712\n",
      "[5] Loss: 0.04329479915369898\n",
      "[6] Loss: 0.03697613977702029\n",
      "[7] Loss: 0.03122086300135358\n",
      "[8] Loss: 0.028642123607523454\n",
      "[9] Loss: 0.02316238466915347\n",
      "[10] Loss: 0.021401189398819777\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(10):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"[{epoch + 1}] Loss: {running_loss / len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8ca9a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 98.94%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7119c2b3",
   "metadata": {},
   "source": [
    "## TensorFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "304b0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "577e1b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "045a8f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values between -1 and 1\n",
    "x_train = (x_train / 255.0) * 2 - 1\n",
    "x_test = (x_test / 255.0) * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a04a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a channel dimension to the images\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0036942f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow Dataset objects\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(128)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63368972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN with less than 10000 parameters\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Conv2D(8, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "    layers.MaxPooling2D(2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56d98e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39895db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 48s 87ms/step - loss: 0.3592 - accuracy: 0.8962\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 38s 81ms/step - loss: 0.0974 - accuracy: 0.9705\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 42s 89ms/step - loss: 0.0670 - accuracy: 0.9798\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 40s 86ms/step - loss: 0.0528 - accuracy: 0.9840\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 37s 80ms/step - loss: 0.0439 - accuracy: 0.9869\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 45s 95ms/step - loss: 0.0368 - accuracy: 0.9891\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 51s 110ms/step - loss: 0.0312 - accuracy: 0.9912\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 44s 94ms/step - loss: 0.0265 - accuracy: 0.9925\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 43s 92ms/step - loss: 0.0225 - accuracy: 0.9939\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 58s 123ms/step - loss: 0.0194 - accuracy: 0.9949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d884cba100>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ae6e690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 5s 30ms/step - loss: 0.0511 - accuracy: 0.9856\n",
      "Validation Accuracy: 98.56%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "print(f\"Validation Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
